{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCL Matrix Multiplication\n",
    "Exercise 3 - Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update -qq\n",
    "!apt-get install -y --no-install-recommends software-properties-common build-essential\n",
    "!apt-get install -y --no-install-recommends ocl-icd-opencl-dev opencl-headers\n",
    "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lscpu | head -n 10\n",
    "!nvidia-smi\n",
    "!clinfo | grep \"Platform Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ocl_matmul.cpp\n",
    "/**\n",
    " * OpenCL Matrix Multiplication - Hybrid CPU + GPU\n",
    " * Exercise 3, Problem 2\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "\n",
    "#ifdef __APPLE__\n",
    "#include <OpenCL/opencl.h>\n",
    "#else\n",
    "#include <CL/cl.h>\n",
    "#endif\n",
    "\n",
    "const char* kernelSource = \n",
    "\"__kernel void matMul(__global const float* A, \\n\"\n",
    "\"                     __global const float* B, \\n\"\n",
    "\"                     __global float* C, \\n\"\n",
    "\"                     const int width, \\n\"\n",
    "\"                     const int rowOffset) { \\n\"\n",
    "\"    int col = get_global_id(0); \\n\" \n",
    "\"    int row = get_global_id(1) + rowOffset; \\n\" // Apply offset\n",
    "\"    \\n\"\n",
    "\"    if (col < width && row < width) { \\n\"\n",
    "\"        float sum = 0.0f; \\n\"\n",
    "\"        for (int k = 0; k < width; k++) { \\n\"\n",
    "\"            sum += A[row * width + k] * B[k * width + col]; \\n\"\n",
    "\"        } \\n\"\n",
    "\"        C[row * width + col] = sum; \\n\"\n",
    "\"    } \\n\"\n",
    "\"}\\n\";\n",
    "\n",
    "void checkError(cl_int error, const char* operation) {\n",
    "    if (error != CL_SUCCESS) {\n",
    "        printf(\"Error during %s: %d\\n\", operation, error);\n",
    "        exit(1);\n",
    "    }\n",
    "}\n",
    "\n",
    "double getCurrentTime() {\n",
    "    struct timespec ts;\n",
    "    clock_gettime(CLOCK_MONOTONIC, &ts);\n",
    "    return ts.tv_sec + ts.tv_nsec / 1e9;\n",
    "}\n",
    "\n",
    "// CPU Matrix Multiplication for a range of rows [startRow, endRow)\n",
    "void matrixMulCPU_Partial(float* A, float* B, float* C, int width, int startRow, int endRow) {\n",
    "    for (int i = startRow; i < endRow; i++) {\n",
    "        for (int j = 0; j < width; j++) {\n",
    "            float sum = 0.0f;\n",
    "            for (int k = 0; k < width; k++) {\n",
    "                sum += A[i * width + k] * B[k * width + j];\n",
    "            }\n",
    "            C[i * width + j] = sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void verify_result(float* h_C, float* h_C_Ref, int width) {\n",
    "    int errors = 0;\n",
    "    for (int i = 0; i < width * width; i++) {\n",
    "        if (fabs(h_C[i] - h_C_Ref[i]) > 1e-3) {\n",
    "            if (errors < 5) printf(\"Mismatch at %d: %.4f vs %.4f\\n\", i, h_C[i], h_C_Ref[i]);\n",
    "            errors++;\n",
    "        }\n",
    "    }\n",
    "    if (errors == 0) printf(\"Verification PASSED\\n\");\n",
    "    else printf(\"Verification FAILED (Errors: %d)\\n\", errors);\n",
    "}\n",
    "\n",
    "void run_benchmark(int width, float gpu_portion, double *totalTimes, int T, int verify) {\n",
    "    size_t size = width * width * sizeof(float);\n",
    "    \n",
    "    // Calculate split\n",
    "    int gpu_rows = (int)(width * gpu_portion);\n",
    "    int cpu_rows = width - gpu_rows;\n",
    "    // CPU does rows [0, cpu_rows)\n",
    "    // GPU does rows [cpu_rows, width)\n",
    "    \n",
    "    if (!verify) {\n",
    "        printf(\"Config: GPU=%.0f%% (Rows %d-%d), CPU=%.0f%% (Rows 0-%d)\\n\", \n",
    "               gpu_portion*100, cpu_rows, width, (1.0-gpu_portion)*100, cpu_rows);\n",
    "    }\n",
    "\n",
    "    float *h_A = (float*)malloc(size);\n",
    "    float *h_B = (float*)malloc(size);\n",
    "    float *h_C = (float*)malloc(size);\n",
    "    float *h_C_Ref = verify ? (float*)malloc(size) : NULL;\n",
    "\n",
    "    srand(2025);\n",
    "    for(int i=0; i<width*width; i++) {\n",
    "        h_A[i] = (float)rand()/RAND_MAX;\n",
    "        h_B[i] = (float)rand()/RAND_MAX;\n",
    "    }\n",
    "    \n",
    "    // Verify: compute full CPU reference first\n",
    "    if (verify) {\n",
    "        printf(\"Computing CPU Reference...\\n\");\n",
    "        matrixMulCPU_Partial(h_A, h_B, h_C_Ref, width, 0, width);\n",
    "    }\n",
    "\n",
    "    // OpenCL Setup\n",
    "    cl_platform_id platform; cl_device_id device; cl_context context; cl_command_queue queue;\n",
    "    cl_program program; cl_kernel kernel; cl_int ret; cl_uint n_plat, n_dev;\n",
    "    \n",
    "    clGetPlatformIDs(1, &platform, &n_plat);\n",
    "    if(clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, 1, &device, &n_dev) != CL_SUCCESS) {\n",
    "        clGetDeviceIDs(platform, CL_DEVICE_TYPE_ALL, 1, &device, &n_dev);\n",
    "    }\n",
    "    \n",
    "    context = clCreateContext(NULL, 1, &device, NULL, NULL, &ret);\n",
    "    queue = clCreateCommandQueue(context, device, 0, &ret);\n",
    "    \n",
    "    cl_mem d_A = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, size, h_A, &ret);\n",
    "    cl_mem d_B = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, size, h_B, &ret);\n",
    "    cl_mem d_C = clCreateBuffer(context, CL_MEM_WRITE_ONLY, size, NULL, &ret); // Full buffer for simplicity\n",
    "    \n",
    "    program = clCreateProgramWithSource(context, 1, &kernelSource, NULL, &ret);\n",
    "    clBuildProgram(program, 1, &device, NULL, NULL, NULL);\n",
    "    kernel = clCreateKernel(program, \"matMul\", &ret);\n",
    "    \n",
    "    // Set fixed args\n",
    "    clSetKernelArg(kernel, 0, sizeof(cl_mem), &d_A);\n",
    "    clSetKernelArg(kernel, 1, sizeof(cl_mem), &d_B);\n",
    "    clSetKernelArg(kernel, 2, sizeof(cl_mem), &d_C);\n",
    "    clSetKernelArg(kernel, 3, sizeof(int), &width);\n",
    "    int rowOffset = cpu_rows;\n",
    "    clSetKernelArg(kernel, 4, sizeof(int), &rowOffset);\n",
    "    \n",
    "    // GPU Work Size\n",
    "    // We only need to compute 'gpu_rows' rows. \n",
    "    // Global Size Y = gpu_rows.\n",
    "    size_t globalSize[2] = { (size_t)width, (size_t)(gpu_rows > 0 ? gpu_rows : 1) };\n",
    "    size_t localSize[2] = { 16, 16 };\n",
    "    // Pad global size if needed... reusing naive logic for now\n",
    "    \n",
    "    int iterations = verify ? 1 : T;\n",
    "    \n",
    "    for(int iter=0; iter<iterations; iter++) {\n",
    "        double start = getCurrentTime();\n",
    "        \n",
    "        // 1. CPU Part\n",
    "        if (cpu_rows > 0) {\n",
    "            matrixMulCPU_Partial(h_A, h_B, h_C, width, 0, cpu_rows);\n",
    "        }\n",
    "        \n",
    "        // 2. GPU Part\n",
    "        if (gpu_rows > 0) {\n",
    "            ret = clEnqueueNDRangeKernel(queue, kernel, 2, NULL, globalSize, localSize, 0, NULL, NULL);\n",
    "            clFinish(queue);\n",
    "            // Read back ONLY the GPU part\n",
    "            size_t offset = cpu_rows * width * sizeof(float);\n",
    "            size_t cb = gpu_rows * width * sizeof(float);\n",
    "            clEnqueueReadBuffer(queue, d_C, CL_TRUE, offset, cb, h_C + (cpu_rows * width), 0, NULL, NULL);\n",
    "        }\n",
    "        \n",
    "        double end = getCurrentTime();\n",
    "        if (totalTimes) totalTimes[iter] = end - start;\n",
    "    }\n",
    "    \n",
    "    if (verify) {\n",
    "        verify_result(h_C, h_C_Ref, width);\n",
    "        free(h_C_Ref);\n",
    "    }\n",
    "    \n",
    "    clReleaseMemObject(d_A); clReleaseMemObject(d_B); clReleaseMemObject(d_C);\n",
    "    clReleaseKernel(kernel); clReleaseProgram(program);\n",
    "    clReleaseCommandQueue(queue); clReleaseContext(context);\n",
    "    free(h_A); free(h_B); free(h_C);\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "    // Usage: ./ocl_matmul [N]\n",
    "    // Default N=1024\n",
    "    int N = 1024;\n",
    "    if (argc > 1) N = atoi(argv[1]);\n",
    "\n",
    "    // 1. Correctness Check (50/50 split)\n",
    "    printf(\"=== Correctness Check (N=%d) ===\\n\", N);\n",
    "    run_benchmark(N, 0.5, NULL, 1, 1);\n",
    "    \n",
    "    // 2. Stress Test Mode (special large inputs)\n",
    "    // If N > 8000, we assume it's a manual stress test run and skip full benchmark loop\n",
    "    if (N > 8000) {\n",
    "        printf(\"\\n=== Stress Test Run (N=%d) ===\\n\", N);\n",
    "        run_benchmark(N, 1.0, NULL, 1, 0);\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    // 3. Benchmark Suite\n",
    "    const int T = 3;\n",
    "    double times[T];\n",
    "    FILE *csv = fopen(\"matmul_results.csv\", \"w\");\n",
    "    if (csv) {\n",
    "        fprintf(csv, \"Portion\");\n",
    "        for(int i=0; i<T; i++) fprintf(csv, \",Run_%d\", i+1);\n",
    "        fprintf(csv, \"\\n\");\n",
    "    }\n",
    "    \n",
    "    float portions[] = {0.0, 0.25, 0.5, 0.75, 1.0};\n",
    "    printf(\"\\n=== Starting Benchmark (N=%d) ===\\n\", N);\n",
    "    for(int p=0; p<5; p++) {\n",
    "        run_benchmark(N, portions[p], times, T, 0);\n",
    "        if (csv) {\n",
    "            fprintf(csv, \"%.2f\", portions[p]);\n",
    "            for(int i=0; i<T; i++) fprintf(csv, \",%.6f\", times[i]);\n",
    "            fprintf(csv, \"\\n\");\n",
    "        }\n",
    "    }\n",
    "    if (csv) fclose(csv);\n",
    "    printf(\"Benchmark Complete. Results in matmul_results.csv\\n\");\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -O3 ocl_matmul.cpp -o ocl_matmul -lOpenCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 3: Small input verification\n",
    "!./ocl_matmul 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 5: Large input test before benchmark\n",
    "!./ocl_matmul 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Benchmark Loop (N=1024)\n",
    "!./ocl_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: VRAM Stress Test (N=10240 ~ 3GB VRAM usage)\n",
    "# Run this cell and capture a screenshot of system/GPU utilization.\n",
    "!./ocl_matmul 10240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('matmul_results.csv')\n",
    "    # Calculate average time\n",
    "    time_cols = [c for c in df.columns if 'Run_' in c]\n",
    "    df['AvgTime'] = df[time_cols].mean(axis=1)\n",
    "    \n",
    "    # Calculate Speedup relative to CPU only (Portion 0.0)\n",
    "    cpu_time = df.loc[df['Portion'] == 0.0, 'AvgTime'].values[0]\n",
    "    df['Speedup'] = cpu_time / df['AvgTime']\n",
    "    \n",
    "    print(df[['Portion', 'AvgTime', 'Speedup']])\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['Portion'], df['Speedup'], marker='o', linewidth=2)\n",
    "    plt.title(\"Amdahl's Law - Matrix Multiplication Speedup\")\n",
    "    plt.xlabel(\"Parallel Portion (GPU Workload)\")\n",
    "    plt.ylabel(\"Speedup (vs Pure CPU)\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig('amdahls_law_matmul.png')\n",
    "    plt.show()\n",
    "    print(\"Plot saved to amdahls_law_matmul.png\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not plot: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Tasks Answers & Discussion\n",
    "1. **Estimation vs Reality (Task 2)**: [Discuss how your rough estimation of improvements matched (or didn't) the actual results. Don't aim for a perfect match, show your learning process.]\n",
    "2. **Speedup Observed**: [Fill in after running benchmark]\n",
    "3. **Amdahl's Law validation**: [Comment on the plot based on the results]\n",
    "4. **VRAM Stress Test**: [Attach your screenshot here showing hardware utilization]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}